{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDT05 Project - Short Report\n",
    "\n",
    "Student: Eivind Lie Andreassen\n",
    "\n",
    "Student ID: 767767\n",
    "\n",
    "Email: eiviland@stud.ntnu.no\n",
    "\n",
    "Challenge ID: 2\n",
    "\n",
    "Challenge Name: Santander Customer Transaction Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style('dark')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "We set a few flags for whether we are running locally and on Kaggle, and whether we want the reduced or full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "IS_LOCAL = True  # Sets whether we are running locally or on kaggle\n",
    "USE_REDUCED = True  # Sets whether we should use the smaller dataset\n",
    "\n",
    "data_index = 2*int(IS_LOCAL) + int(USE_REDUCED)\n",
    "train_path = ('../input/santander-customer-transaction-prediction/train.csv',\n",
    "             '../input/santandersmall/train_small.csv',\n",
    "             'train.csv',\n",
    "             'train_small.csv')[data_index]\n",
    "test_path = ('../input/santander-customer-transaction-prediction/test.csv',\n",
    "             '../input/santandersmall/test_small_with_targets.csv',\n",
    "             'test.csv',\n",
    "             'test_small.csv')[data_index]\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train_df.columns if col not in ['target', 'ID_code']]\n",
    "if not 'target' in test_df:\n",
    "    test_df['target'] = -1\n",
    "\n",
    "all_df = pd.concat([train_df, test_df], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing fake test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987200fc4d0847a7aff3fad526549c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real: 70065\n",
      "Synthetic: 0\n"
     ]
    }
   ],
   "source": [
    "unique_count = np.zeros((test_df.shape[0], len(features)))\n",
    "\n",
    "for f, feature in tqdm(enumerate(features), total=len(features)):\n",
    "    _, i, c = np.unique(test_df[feature], return_counts=True, return_index=True)\n",
    "    unique_count[i[c == 1], f] += 1\n",
    "\n",
    "real_sample_indices = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_sample_indices = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "print('Real:', len(real_sample_indices))\n",
    "print('Synthetic:', len(synthetic_sample_indices))\n",
    "\n",
    "del unique_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1bb199536a4b3cb10b167b1897b195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_real_df = pd.concat([train_df, test_df.iloc[real_sample_indices, :]], sort=False)\n",
    "\n",
    "for feature in tqdm(features):\n",
    "    real_series = all_real_df[feature]\n",
    "    \n",
    "    # We only use the real samples to produce the count\n",
    "    counts = real_series.groupby(real_series).count()\n",
    "    \n",
    "    full_series = all_df[feature]\n",
    "    all_df[f'{feature}_count'] = full_series.map(counts)\n",
    "\n",
    "del all_real_df\n",
    "del real_series\n",
    "del full_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['sum'] = all_df[features].sum(axis=1)\n",
    "all_df['mean'] = all_df[features].mean(axis=1)\n",
    "all_df['min'] = all_df[features].min(axis=1)\n",
    "all_df['max'] = all_df[features].max(axis=1)\n",
    "all_df['std'] = all_df[features].std(axis=1)\n",
    "all_df['median'] = all_df[features].median(axis=1)\n",
    "all_df['skew'] = all_df[features].skew(axis=1)\n",
    "all_df['kurt'] = all_df[features].kurt(axis=1)\n",
    "\n",
    "statistical_features = ['mean', 'min', 'max', 'std', 'median', 'skew', 'kurt']\n",
    "# Due to normalization, mean and sum become the same value, so we only include one of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cef930c1b3f43a08702392c36f07408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=207), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in tqdm(features + statistical_features):\n",
    "    if feature in features:\n",
    "        all_df[feature] = StandardScaler().fit_transform(all_df[feature].values.reshape(-1, 1))\n",
    "        all_df[f'{feature}_count'] = MinMaxScaler().fit_transform(all_df[f'{feature}_count'].values.reshape(-1, 1))\n",
    "    if feature in statistical_features:\n",
    "        all_df[feature] = StandardScaler().fit_transform(all_df[feature].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(len(features)):\n",
    "    features.append(f'{features[f]}_count')\n",
    "features.extend(statistical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting datasets back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = all_df.iloc[:train_df.shape[0], :]\n",
    "test_df = all_df.iloc[train_df.shape[0]:, :]\n",
    "\n",
    "del all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regularized_cnn_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Reshape((len(features) * 1, 1), input_shape=(len(features) * 1,)),\n",
    "        tf.keras.layers.Conv1D(32, 1, activation='elu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv1D(64, 1, activation='elu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "EARLY_STOPPING_PATIENCE = 8\n",
    "\n",
    "OPTIMIZER = tf.keras.optimizers.Nadam()\n",
    "LOSS='binary_crossentropy'\n",
    "METRICS=[tf.keras.metrics.AUC()]\n",
    "\n",
    "model_fn = get_regularized_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76cbf68482184a368c3a5978729ff482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5:\n",
      "Train on 56045 samples, validate on 14012 samples\n",
      "Epoch 1/100\n",
      "56045/56045 [==============================] - 24s 431us/sample - loss: 2.5725 - auc: 0.7397 - val_loss: 1.0123 - val_auc: 0.6413\n",
      "Epoch 2/100\n",
      "56045/56045 [==============================] - 17s 306us/sample - loss: 0.6264 - auc: 0.8323 - val_loss: 0.6546 - val_auc: 0.5979\n",
      "Epoch 3/100\n",
      "56045/56045 [==============================] - 18s 312us/sample - loss: 0.3908 - auc: 0.8471 - val_loss: 0.3759 - val_auc: 0.8297\n",
      "Epoch 4/100\n",
      "56045/56045 [==============================] - 17s 312us/sample - loss: 0.3593 - auc: 0.8418 - val_loss: 0.3943 - val_auc: 0.8489\n",
      "Epoch 5/100\n",
      "56045/56045 [==============================] - 17s 309us/sample - loss: 0.3629 - auc: 0.8460 - val_loss: 0.3792 - val_auc: 0.8350\n",
      "Epoch 6/100\n",
      "56045/56045 [==============================] - 17s 303us/sample - loss: 0.3766 - auc: 0.8453 - val_loss: 0.4250 - val_auc: 0.8462\n",
      "Epoch 7/100\n",
      "56045/56045 [==============================] - 17s 305us/sample - loss: 0.3992 - auc: 0.8481 - val_loss: 0.4148 - val_auc: 0.8488\n",
      "Epoch 8/100\n",
      "56045/56045 [==============================] - 18s 319us/sample - loss: 0.4199 - auc: 0.8522 - val_loss: 0.4534 - val_auc: 0.8375\n",
      "Epoch 9/100\n",
      "56045/56045 [==============================] - 17s 311us/sample - loss: 0.3996 - auc: 0.8570 - val_loss: 0.4358 - val_auc: 0.8474\n",
      "Epoch 10/100\n",
      "56045/56045 [==============================] - 17s 312us/sample - loss: 0.3897 - auc: 0.8569 - val_loss: 0.3986 - val_auc: 0.8481\n",
      "Epoch 11/100\n",
      "56045/56045 [==============================] - 18s 316us/sample - loss: 0.4002 - auc: 0.8592 - val_loss: 0.4094 - val_auc: 0.8576\n",
      "Epoch 12/100\n",
      "56045/56045 [==============================] - 18s 313us/sample - loss: 0.3893 - auc: 0.8622 - val_loss: 0.4597 - val_auc: 0.8590\n",
      "Epoch 13/100\n",
      "56045/56045 [==============================] - 17s 310us/sample - loss: 0.3934 - auc: 0.8628 - val_loss: 0.4061 - val_auc: 0.8563\n",
      "Epoch 14/100\n",
      "56045/56045 [==============================] - 17s 306us/sample - loss: 0.3849 - auc: 0.8648 - val_loss: 0.4056 - val_auc: 0.8600\n",
      "Epoch 15/100\n",
      "56045/56045 [==============================] - 17s 303us/sample - loss: 0.3906 - auc: 0.8658 - val_loss: 0.3908 - val_auc: 0.8598\n",
      "Epoch 16/100\n",
      "56045/56045 [==============================] - 17s 303us/sample - loss: 0.3784 - auc: 0.8679 - val_loss: 0.3818 - val_auc: 0.8632\n",
      "Epoch 17/100\n",
      "56045/56045 [==============================] - 17s 301us/sample - loss: 0.3783 - auc: 0.8689 - val_loss: 0.5856 - val_auc: 0.8624\n",
      "Epoch 18/100\n",
      "56045/56045 [==============================] - 17s 305us/sample - loss: 0.3656 - auc: 0.8718 - val_loss: 0.3612 - val_auc: 0.8715\n",
      "Epoch 19/100\n",
      "56045/56045 [==============================] - 17s 302us/sample - loss: 0.3649 - auc: 0.8718 - val_loss: 0.3842 - val_auc: 0.8545\n",
      "Epoch 20/100\n",
      "56045/56045 [==============================] - 17s 303us/sample - loss: 0.3572 - auc: 0.8728 - val_loss: 0.3608 - val_auc: 0.8732\n",
      "Epoch 21/100\n",
      "56045/56045 [==============================] - 17s 302us/sample - loss: 0.3521 - auc: 0.8761 - val_loss: 0.3532 - val_auc: 0.8637\n",
      "Epoch 22/100\n",
      "56045/56045 [==============================] - 17s 308us/sample - loss: 0.3528 - auc: 0.8766 - val_loss: 0.3624 - val_auc: 0.8756\n",
      "Epoch 23/100\n",
      "56045/56045 [==============================] - 18s 312us/sample - loss: 0.3438 - auc: 0.8790 - val_loss: 0.3408 - val_auc: 0.8763\n",
      "Epoch 24/100\n",
      "56045/56045 [==============================] - 17s 311us/sample - loss: 0.3326 - auc: 0.8810 - val_loss: 0.3497 - val_auc: 0.8663\n",
      "Epoch 25/100\n",
      "56045/56045 [==============================] - 17s 312us/sample - loss: 0.3347 - auc: 0.8814 - val_loss: 0.3582 - val_auc: 0.8684\n",
      "Epoch 26/100\n",
      "56045/56045 [==============================] - 18s 314us/sample - loss: 0.3217 - auc: 0.8827 - val_loss: 0.3423 - val_auc: 0.8706\n",
      "Epoch 27/100\n",
      "56045/56045 [==============================] - 18s 314us/sample - loss: 0.3084 - auc: 0.8827 - val_loss: 0.2968 - val_auc: 0.8845\n",
      "Epoch 28/100\n",
      "56045/56045 [==============================] - 17s 312us/sample - loss: 0.2988 - auc: 0.8850 - val_loss: 0.3003 - val_auc: 0.8815\n",
      "Epoch 29/100\n",
      "56045/56045 [==============================] - 17s 312us/sample - loss: 0.2917 - auc: 0.8860 - val_loss: 0.3075 - val_auc: 0.8795\n",
      "Epoch 30/100\n",
      "56045/56045 [==============================] - 18s 313us/sample - loss: 0.2851 - auc: 0.8866 - val_loss: 0.2993 - val_auc: 0.8829\n",
      "Epoch 31/100\n",
      "56045/56045 [==============================] - 17s 312us/sample - loss: 0.2810 - auc: 0.8869 - val_loss: 0.3616 - val_auc: 0.8833\n",
      "Epoch 32/100\n",
      "56045/56045 [==============================] - 17s 311us/sample - loss: 0.2700 - auc: 0.8874 - val_loss: 0.2684 - val_auc: 0.8817\n",
      "Epoch 33/100\n",
      "56045/56045 [==============================] - 17s 312us/sample - loss: 0.2600 - auc: 0.8885 - val_loss: 0.2527 - val_auc: 0.8844\n",
      "Epoch 34/100\n",
      "56045/56045 [==============================] - 17s 300us/sample - loss: 0.2553 - auc: 0.8896 - val_loss: 0.2876 - val_auc: 0.8744\n",
      "Epoch 35/100\n",
      "56045/56045 [==============================] - 17s 302us/sample - loss: 0.2511 - auc: 0.8897 - val_loss: 0.2636 - val_auc: 0.8806\n",
      "Creating predictions for fold 1/5\n",
      "Fold validation AUC: 0.8845454774346373\n",
      "\n",
      "Fold 2/5:\n",
      "Train on 56045 samples, validate on 14012 samples\n",
      "Epoch 1/100\n",
      "56045/56045 [==============================] - 21s 378us/sample - loss: 1.8611 - auc: 0.7718 - val_loss: 0.6297 - val_auc: 0.5500\n",
      "Epoch 2/100\n",
      "56045/56045 [==============================] - 17s 311us/sample - loss: 0.4545 - auc: 0.8318 - val_loss: 0.6238 - val_auc: 0.6977\n",
      "Epoch 3/100\n",
      "56045/56045 [==============================] - 18s 313us/sample - loss: 0.4735 - auc: 0.8411 - val_loss: 0.4919 - val_auc: 0.8205\n",
      "Epoch 4/100\n",
      "56045/56045 [==============================] - 17s 310us/sample - loss: 0.4763 - auc: 0.8474 - val_loss: 0.5995 - val_auc: 0.8470\n",
      "Epoch 5/100\n",
      "56045/56045 [==============================] - 17s 308us/sample - loss: 0.4562 - auc: 0.8542 - val_loss: 0.5184 - val_auc: 0.8248\n",
      "Epoch 6/100\n",
      "56045/56045 [==============================] - 17s 310us/sample - loss: 0.4439 - auc: 0.8595 - val_loss: 0.4470 - val_auc: 0.8565\n",
      "Epoch 7/100\n",
      "56045/56045 [==============================] - 17s 310us/sample - loss: 0.4395 - auc: 0.8629 - val_loss: 0.4671 - val_auc: 0.8650\n",
      "Epoch 8/100\n",
      "56045/56045 [==============================] - 17s 308us/sample - loss: 0.4458 - auc: 0.8671 - val_loss: 0.4788 - val_auc: 0.8586\n",
      "Epoch 9/100\n",
      "56045/56045 [==============================] - 17s 309us/sample - loss: 0.4303 - auc: 0.8710 - val_loss: 0.4149 - val_auc: 0.8609\n",
      "Epoch 10/100\n",
      "56045/56045 [==============================] - 17s 307us/sample - loss: 0.4175 - auc: 0.8738 - val_loss: 0.5603 - val_auc: 0.8718\n",
      "Epoch 11/100\n",
      "56045/56045 [==============================] - 17s 311us/sample - loss: 0.3993 - auc: 0.8760 - val_loss: 0.4808 - val_auc: 0.8762\n",
      "Epoch 12/100\n",
      "56045/56045 [==============================] - 17s 309us/sample - loss: 0.3877 - auc: 0.8776 - val_loss: 0.4067 - val_auc: 0.8654\n",
      "Epoch 13/100\n",
      "56045/56045 [==============================] - 17s 310us/sample - loss: 0.3768 - auc: 0.8809 - val_loss: 0.4825 - val_auc: 0.8697\n",
      "Epoch 14/100\n",
      "56045/56045 [==============================] - 17s 311us/sample - loss: 0.3591 - auc: 0.8814 - val_loss: 0.4135 - val_auc: 0.8681\n",
      "Epoch 15/100\n",
      "56045/56045 [==============================] - 17s 311us/sample - loss: 0.3511 - auc: 0.8836 - val_loss: 0.3609 - val_auc: 0.8775\n",
      "Epoch 16/100\n",
      "56045/56045 [==============================] - 17s 310us/sample - loss: 0.3556 - auc: 0.8847 - val_loss: 0.3542 - val_auc: 0.8619\n",
      "Epoch 17/100\n",
      "56045/56045 [==============================] - 18s 314us/sample - loss: 0.3422 - auc: 0.8863 - val_loss: 0.3404 - val_auc: 0.8687\n",
      "Epoch 18/100\n",
      "56045/56045 [==============================] - 17s 311us/sample - loss: 0.3323 - auc: 0.8869 - val_loss: 0.3373 - val_auc: 0.8744\n",
      "Epoch 19/100\n",
      "56045/56045 [==============================] - 17s 310us/sample - loss: 0.3280 - auc: 0.8886 - val_loss: 0.3342 - val_auc: 0.8734\n",
      "Epoch 20/100\n",
      "56045/56045 [==============================] - 18s 322us/sample - loss: 0.3200 - auc: 0.8882 - val_loss: 0.3318 - val_auc: 0.8758\n",
      "Epoch 21/100\n",
      "56045/56045 [==============================] - 18s 313us/sample - loss: 0.3030 - auc: 0.8900 - val_loss: 0.3012 - val_auc: 0.8762\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56045/56045 [==============================] - 17s 302us/sample - loss: 0.2988 - auc: 0.8910 - val_loss: 0.3003 - val_auc: 0.8775\n",
      "Epoch 23/100\n",
      "56045/56045 [==============================] - 17s 302us/sample - loss: 0.3041 - auc: 0.8914 - val_loss: 0.3024 - val_auc: 0.8715\n",
      "Epoch 24/100\n",
      "56045/56045 [==============================] - 17s 302us/sample - loss: 0.2888 - auc: 0.8912 - val_loss: 0.2955 - val_auc: 0.8809\n",
      "Epoch 25/100\n",
      "56045/56045 [==============================] - 17s 302us/sample - loss: 0.2686 - auc: 0.8931 - val_loss: 0.2584 - val_auc: 0.8826\n",
      "Epoch 26/100\n",
      "56045/56045 [==============================] - 17s 307us/sample - loss: 0.2627 - auc: 0.8923 - val_loss: 0.2615 - val_auc: 0.8845\n",
      "Epoch 27/100\n",
      "56045/56045 [==============================] - 17s 310us/sample - loss: 0.2573 - auc: 0.8932 - val_loss: 0.3526 - val_auc: 0.8846\n",
      "Epoch 28/100\n",
      "56045/56045 [==============================] - 18s 314us/sample - loss: 0.2529 - auc: 0.8934 - val_loss: 0.2529 - val_auc: 0.8823\n",
      "Epoch 29/100\n",
      "56045/56045 [==============================] - 18s 315us/sample - loss: 0.2465 - auc: 0.8944 - val_loss: 0.2667 - val_auc: 0.8799\n",
      "Epoch 30/100\n",
      "56045/56045 [==============================] - 17s 311us/sample - loss: 0.2509 - auc: 0.8948 - val_loss: 0.2846 - val_auc: 0.8816\n",
      "Epoch 31/100\n",
      "56045/56045 [==============================] - 18s 315us/sample - loss: 0.2412 - auc: 0.8958 - val_loss: 0.2429 - val_auc: 0.8849\n",
      "Epoch 32/100\n",
      "56045/56045 [==============================] - 17s 311us/sample - loss: 0.2340 - auc: 0.8955 - val_loss: 0.5149 - val_auc: 0.7789\n",
      "Epoch 33/100\n",
      "56045/56045 [==============================] - 18s 314us/sample - loss: 0.2277 - auc: 0.8962 - val_loss: 0.2451 - val_auc: 0.8840\n",
      "Epoch 34/100\n",
      "56045/56045 [==============================] - 18s 314us/sample - loss: 0.2261 - auc: 0.8970 - val_loss: 0.2438 - val_auc: 0.8835\n",
      "Epoch 35/100\n",
      "56045/56045 [==============================] - 18s 313us/sample - loss: 0.2273 - auc: 0.8963 - val_loss: 0.2400 - val_auc: 0.8835\n",
      "Epoch 36/100\n",
      "56045/56045 [==============================] - 17s 312us/sample - loss: 0.2243 - auc: 0.8968 - val_loss: 0.2973 - val_auc: 0.8817\n",
      "Epoch 37/100\n",
      "56045/56045 [==============================] - 18s 313us/sample - loss: 0.2219 - auc: 0.8970 - val_loss: 0.2343 - val_auc: 0.8841\n",
      "Epoch 38/100\n",
      "56045/56045 [==============================] - 17s 310us/sample - loss: 0.2215 - auc: 0.8986 - val_loss: 0.2534 - val_auc: 0.8812\n",
      "Epoch 39/100\n",
      "56045/56045 [==============================] - 17s 312us/sample - loss: 0.2194 - auc: 0.8987 - val_loss: 0.2326 - val_auc: 0.8820\n",
      "Creating predictions for fold 2/5\n",
      "Fold validation AUC: 0.8851989172055574\n",
      "\n",
      "Fold 3/5:\n",
      "Train on 56046 samples, validate on 14011 samples\n",
      "Epoch 1/100\n",
      "56046/56046 [==============================] - 21s 381us/sample - loss: 2.3297 - auc: 0.7702 - val_loss: 0.7491 - val_auc: 0.5004\n",
      "Epoch 2/100\n",
      "56046/56046 [==============================] - 17s 306us/sample - loss: 0.4549 - auc: 0.8264 - val_loss: 0.6050 - val_auc: 0.7429\n",
      "Epoch 3/100\n",
      "56046/56046 [==============================] - 17s 307us/sample - loss: 0.4616 - auc: 0.8346 - val_loss: 0.4859 - val_auc: 0.8274\n",
      "Epoch 4/100\n",
      "56046/56046 [==============================] - 17s 302us/sample - loss: 0.4697 - auc: 0.8424 - val_loss: 0.5962 - val_auc: 0.8390\n",
      "Epoch 5/100\n",
      "56046/56046 [==============================] - 17s 301us/sample - loss: 0.4654 - auc: 0.8496 - val_loss: 0.4312 - val_auc: 0.8534\n",
      "Epoch 6/100\n",
      "56046/56046 [==============================] - 17s 301us/sample - loss: 0.4369 - auc: 0.8532 - val_loss: 0.4487 - val_auc: 0.8390\n",
      "Epoch 7/100\n",
      "56046/56046 [==============================] - 17s 305us/sample - loss: 0.4226 - auc: 0.8563 - val_loss: 0.4551 - val_auc: 0.8535\n",
      "Epoch 8/100\n",
      "56046/56046 [==============================] - 17s 307us/sample - loss: 0.4235 - auc: 0.8607 - val_loss: 0.4519 - val_auc: 0.8698\n",
      "Epoch 9/100\n",
      "56046/56046 [==============================] - 17s 307us/sample - loss: 0.4119 - auc: 0.8648 - val_loss: 0.4369 - val_auc: 0.8531\n",
      "Epoch 10/100\n",
      "56046/56046 [==============================] - 17s 308us/sample - loss: 0.4150 - auc: 0.8661 - val_loss: 0.4308 - val_auc: 0.8525\n",
      "Epoch 11/100\n",
      "56046/56046 [==============================] - 17s 312us/sample - loss: 0.4015 - auc: 0.8699 - val_loss: 0.4014 - val_auc: 0.8682\n",
      "Epoch 12/100\n",
      "56046/56046 [==============================] - 18s 313us/sample - loss: 0.3974 - auc: 0.8698 - val_loss: 0.4285 - val_auc: 0.8677\n",
      "Epoch 13/100\n",
      "56046/56046 [==============================] - 17s 308us/sample - loss: 0.3829 - auc: 0.8743 - val_loss: 0.3618 - val_auc: 0.8682\n",
      "Epoch 14/100\n",
      "56046/56046 [==============================] - 17s 311us/sample - loss: 0.3769 - auc: 0.8751 - val_loss: 0.4763 - val_auc: 0.8659\n",
      "Epoch 15/100\n",
      "56046/56046 [==============================] - 17s 311us/sample - loss: 0.3650 - auc: 0.8760 - val_loss: 0.3747 - val_auc: 0.8664\n",
      "Epoch 16/100\n",
      "56046/56046 [==============================] - 17s 312us/sample - loss: 0.3626 - auc: 0.8779 - val_loss: 0.4099 - val_auc: 0.8797\n",
      "Epoch 17/100\n",
      "56046/56046 [==============================] - 17s 311us/sample - loss: 0.3464 - auc: 0.8797 - val_loss: 0.3320 - val_auc: 0.8806\n",
      "Epoch 18/100\n",
      "56046/56046 [==============================] - 17s 307us/sample - loss: 0.3332 - auc: 0.8840 - val_loss: 0.4123 - val_auc: 0.8795\n",
      "Epoch 19/100\n",
      "56046/56046 [==============================] - 17s 308us/sample - loss: 0.3217 - auc: 0.8853 - val_loss: 0.3217 - val_auc: 0.8759\n",
      "Epoch 20/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.3133 - auc: 0.8867 - val_loss: 0.2977 - val_auc: 0.8859\n",
      "Epoch 21/100\n",
      "56046/56046 [==============================] - 17s 307us/sample - loss: 0.2977 - auc: 0.8901 - val_loss: 0.2935 - val_auc: 0.8823\n",
      "Epoch 22/100\n",
      "56046/56046 [==============================] - 17s 308us/sample - loss: 0.2761 - auc: 0.8897 - val_loss: 0.2899 - val_auc: 0.8811\n",
      "Epoch 23/100\n",
      "56046/56046 [==============================] - 17s 311us/sample - loss: 0.2672 - auc: 0.8908 - val_loss: 0.2652 - val_auc: 0.8854\n",
      "Epoch 24/100\n",
      "56046/56046 [==============================] - 17s 311us/sample - loss: 0.2628 - auc: 0.8916 - val_loss: 0.2709 - val_auc: 0.8849\n",
      "Epoch 25/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.2568 - auc: 0.8937 - val_loss: 0.2615 - val_auc: 0.8797\n",
      "Epoch 26/100\n",
      "56046/56046 [==============================] - 17s 311us/sample - loss: 0.2485 - auc: 0.8938 - val_loss: 0.2423 - val_auc: 0.8888\n",
      "Epoch 27/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.2370 - auc: 0.8948 - val_loss: 0.2505 - val_auc: 0.8869\n",
      "Epoch 28/100\n",
      "56046/56046 [==============================] - 18s 314us/sample - loss: 0.2339 - auc: 0.8933 - val_loss: 0.2383 - val_auc: 0.8874\n",
      "Epoch 29/100\n",
      "56046/56046 [==============================] - 17s 312us/sample - loss: 0.2356 - auc: 0.8940 - val_loss: 0.2308 - val_auc: 0.8871\n",
      "Epoch 30/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.2266 - auc: 0.8957 - val_loss: 0.2327 - val_auc: 0.8881\n",
      "Epoch 31/100\n",
      "56046/56046 [==============================] - 18s 313us/sample - loss: 0.2246 - auc: 0.8956 - val_loss: 0.2353 - val_auc: 0.8891\n",
      "Epoch 32/100\n",
      "56046/56046 [==============================] - 18s 313us/sample - loss: 0.2242 - auc: 0.8961 - val_loss: 0.2349 - val_auc: 0.8898\n",
      "Epoch 33/100\n",
      "56046/56046 [==============================] - 17s 312us/sample - loss: 0.2210 - auc: 0.8973 - val_loss: 0.2347 - val_auc: 0.8896\n",
      "Epoch 34/100\n",
      "56046/56046 [==============================] - 18s 312us/sample - loss: 0.2199 - auc: 0.8966 - val_loss: 0.3014 - val_auc: 0.8866\n",
      "Epoch 35/100\n",
      "56046/56046 [==============================] - 18s 313us/sample - loss: 0.2177 - auc: 0.8962 - val_loss: 0.2597 - val_auc: 0.8907\n",
      "Epoch 36/100\n",
      "56046/56046 [==============================] - 17s 311us/sample - loss: 0.2164 - auc: 0.8969 - val_loss: 0.2255 - val_auc: 0.8903\n",
      "Epoch 37/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.2230 - auc: 0.8976 - val_loss: 0.2265 - val_auc: 0.8884\n",
      "Epoch 38/100\n",
      "56046/56046 [==============================] - 17s 311us/sample - loss: 0.2165 - auc: 0.8977 - val_loss: 0.2274 - val_auc: 0.8887\n",
      "Epoch 39/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.2150 - auc: 0.8981 - val_loss: 0.2210 - val_auc: 0.8882\n",
      "Epoch 40/100\n",
      "56046/56046 [==============================] - 17s 308us/sample - loss: 0.2165 - auc: 0.8986 - val_loss: 0.9964 - val_auc: 0.8904\n",
      "Epoch 41/100\n",
      "56046/56046 [==============================] - 17s 307us/sample - loss: 0.2155 - auc: 0.8990 - val_loss: 0.2532 - val_auc: 0.8851\n",
      "Epoch 42/100\n",
      "56046/56046 [==============================] - 17s 302us/sample - loss: 0.2159 - auc: 0.8982 - val_loss: 0.2298 - val_auc: 0.8869\n",
      "Epoch 43/100\n",
      "56046/56046 [==============================] - 17s 311us/sample - loss: 0.2138 - auc: 0.8992 - val_loss: 0.2202 - val_auc: 0.8858\n",
      "Creating predictions for fold 3/5\n",
      "Fold validation AUC: 0.8907000084781553\n",
      "\n",
      "Fold 4/5:\n",
      "Train on 56046 samples, validate on 14011 samples\n",
      "Epoch 1/100\n",
      "56046/56046 [==============================] - 22s 386us/sample - loss: 2.3561 - auc: 0.7729 - val_loss: 0.6873 - val_auc: 0.5664\n",
      "Epoch 2/100\n",
      "56046/56046 [==============================] - 17s 312us/sample - loss: 0.5084 - auc: 0.8275 - val_loss: 0.6184 - val_auc: 0.7747\n",
      "Epoch 3/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.4889 - auc: 0.8393 - val_loss: 0.4834 - val_auc: 0.8404\n",
      "Epoch 4/100\n",
      "56046/56046 [==============================] - 17s 305us/sample - loss: 0.4897 - auc: 0.8471 - val_loss: 0.5622 - val_auc: 0.8569\n",
      "Epoch 5/100\n",
      "56046/56046 [==============================] - 17s 305us/sample - loss: 0.4539 - auc: 0.8549 - val_loss: 0.4606 - val_auc: 0.8503\n",
      "Epoch 6/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.4585 - auc: 0.8575 - val_loss: 0.5033 - val_auc: 0.8442\n",
      "Epoch 7/100\n",
      "56046/56046 [==============================] - 17s 312us/sample - loss: 0.4648 - auc: 0.8578 - val_loss: 0.4128 - val_auc: 0.8638\n",
      "Epoch 8/100\n",
      "56046/56046 [==============================] - 17s 312us/sample - loss: 0.4372 - auc: 0.8617 - val_loss: 0.4238 - val_auc: 0.8642\n",
      "Epoch 9/100\n",
      "56046/56046 [==============================] - 17s 311us/sample - loss: 0.4178 - auc: 0.8641 - val_loss: 0.7707 - val_auc: 0.8715\n",
      "Epoch 10/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.4129 - auc: 0.8690 - val_loss: 0.5081 - val_auc: 0.8658\n",
      "Epoch 11/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.4021 - auc: 0.8680 - val_loss: 0.4025 - val_auc: 0.8667\n",
      "Epoch 12/100\n",
      "56046/56046 [==============================] - 18s 313us/sample - loss: 0.3880 - auc: 0.8713 - val_loss: 0.3886 - val_auc: 0.8731\n",
      "Epoch 13/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.3837 - auc: 0.8721 - val_loss: 0.3668 - val_auc: 0.8587\n",
      "Epoch 14/100\n",
      "56046/56046 [==============================] - 17s 308us/sample - loss: 0.3679 - auc: 0.8750 - val_loss: 0.3778 - val_auc: 0.8643\n",
      "Epoch 15/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.3555 - auc: 0.8758 - val_loss: 0.3877 - val_auc: 0.8726\n",
      "Epoch 16/100\n",
      "56046/56046 [==============================] - 18s 313us/sample - loss: 0.3512 - auc: 0.8767 - val_loss: 0.8362 - val_auc: 0.8757\n",
      "Epoch 17/100\n",
      "56046/56046 [==============================] - 17s 312us/sample - loss: 0.3367 - auc: 0.8803 - val_loss: 0.3177 - val_auc: 0.8820\n",
      "Epoch 18/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.3241 - auc: 0.8814 - val_loss: 0.3355 - val_auc: 0.8727\n",
      "Epoch 19/100\n",
      "56046/56046 [==============================] - 17s 308us/sample - loss: 0.3207 - auc: 0.8840 - val_loss: 0.3365 - val_auc: 0.8774\n",
      "Epoch 20/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.3183 - auc: 0.8828 - val_loss: 0.3317 - val_auc: 0.8827\n",
      "Epoch 21/100\n",
      "56046/56046 [==============================] - 17s 306us/sample - loss: 0.3036 - auc: 0.8855 - val_loss: 0.3068 - val_auc: 0.8792\n",
      "Epoch 22/100\n",
      "56046/56046 [==============================] - 17s 306us/sample - loss: 0.2847 - auc: 0.8865 - val_loss: 0.2969 - val_auc: 0.8823\n",
      "Epoch 23/100\n",
      "56046/56046 [==============================] - 17s 306us/sample - loss: 0.2859 - auc: 0.8887 - val_loss: 0.2812 - val_auc: 0.8825\n",
      "Epoch 24/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.2792 - auc: 0.8885 - val_loss: 0.3019 - val_auc: 0.8836\n",
      "Epoch 25/100\n",
      "56046/56046 [==============================] - 17s 308us/sample - loss: 0.2629 - auc: 0.8913 - val_loss: 0.2663 - val_auc: 0.8823\n",
      "Epoch 26/100\n",
      "56046/56046 [==============================] - 17s 306us/sample - loss: 0.2600 - auc: 0.8924 - val_loss: 0.2798 - val_auc: 0.8821\n",
      "Epoch 27/100\n",
      "56046/56046 [==============================] - 17s 306us/sample - loss: 0.2550 - auc: 0.8935 - val_loss: 0.2563 - val_auc: 0.8825\n",
      "Epoch 28/100\n",
      "56046/56046 [==============================] - 17s 305us/sample - loss: 0.2404 - auc: 0.8950 - val_loss: 0.2480 - val_auc: 0.8831\n",
      "Epoch 29/100\n",
      "56046/56046 [==============================] - 17s 305us/sample - loss: 0.2334 - auc: 0.8954 - val_loss: 0.2449 - val_auc: 0.8790\n",
      "Epoch 30/100\n",
      "56046/56046 [==============================] - 17s 307us/sample - loss: 0.2279 - auc: 0.8956 - val_loss: 0.2361 - val_auc: 0.8860\n",
      "Epoch 31/100\n",
      "56046/56046 [==============================] - 17s 308us/sample - loss: 0.2245 - auc: 0.8971 - val_loss: 0.2333 - val_auc: 0.8871\n",
      "Epoch 32/100\n",
      "56046/56046 [==============================] - 17s 305us/sample - loss: 0.2248 - auc: 0.8958 - val_loss: 0.2327 - val_auc: 0.8860\n",
      "Epoch 33/100\n",
      "56046/56046 [==============================] - 17s 306us/sample - loss: 0.2170 - auc: 0.8987 - val_loss: 0.2271 - val_auc: 0.8858\n",
      "Epoch 34/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.2162 - auc: 0.8994 - val_loss: 0.2288 - val_auc: 0.8858\n",
      "Epoch 35/100\n",
      "56046/56046 [==============================] - 17s 306us/sample - loss: 0.2168 - auc: 0.8993 - val_loss: 0.2466 - val_auc: 0.8861\n",
      "Epoch 36/100\n",
      "56046/56046 [==============================] - 17s 308us/sample - loss: 0.2147 - auc: 0.9004 - val_loss: 0.2374 - val_auc: 0.8845\n",
      "Epoch 37/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.2139 - auc: 0.9002 - val_loss: 0.3551 - val_auc: 0.8804\n",
      "Epoch 38/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.2134 - auc: 0.9012 - val_loss: 0.2604 - val_auc: 0.8856\n",
      "Epoch 39/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.2120 - auc: 0.9013 - val_loss: 0.2301 - val_auc: 0.8855\n",
      "Creating predictions for fold 4/5\n",
      "Fold validation AUC: 0.8872615036479334\n",
      "\n",
      "Fold 5/5:\n",
      "Train on 56046 samples, validate on 14011 samples\n",
      "Epoch 1/100\n",
      "56046/56046 [==============================] - 22s 387us/sample - loss: 2.2931 - auc: 0.7664 - val_loss: 0.6737 - val_auc: 0.6830\n",
      "Epoch 2/100\n",
      "56046/56046 [==============================] - 17s 308us/sample - loss: 0.5139 - auc: 0.8260 - val_loss: 0.6595 - val_auc: 0.7415\n",
      "Epoch 3/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.5084 - auc: 0.8431 - val_loss: 0.5662 - val_auc: 0.7795\n",
      "Epoch 4/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.4997 - auc: 0.8515 - val_loss: 0.4994 - val_auc: 0.8301\n",
      "Epoch 5/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.4921 - auc: 0.8558 - val_loss: 0.5460 - val_auc: 0.8403\n",
      "Epoch 6/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.4716 - auc: 0.8576 - val_loss: 0.6049 - val_auc: 0.8659\n",
      "Epoch 7/100\n",
      "56046/56046 [==============================] - 17s 311us/sample - loss: 0.4590 - auc: 0.8644 - val_loss: 0.4429 - val_auc: 0.8663\n",
      "Epoch 8/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.4445 - auc: 0.8654 - val_loss: 0.4308 - val_auc: 0.8763\n",
      "Epoch 9/100\n",
      "56046/56046 [==============================] - 17s 299us/sample - loss: 0.4433 - auc: 0.8666 - val_loss: 0.4647 - val_auc: 0.8748\n",
      "Epoch 10/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.4238 - auc: 0.8719 - val_loss: 0.4390 - val_auc: 0.8590\n",
      "Epoch 11/100\n",
      "56046/56046 [==============================] - 18s 316us/sample - loss: 0.4362 - auc: 0.8723 - val_loss: 0.7403 - val_auc: 0.8816\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56046/56046 [==============================] - 17s 306us/sample - loss: 0.4067 - auc: 0.8758 - val_loss: 0.4399 - val_auc: 0.8686\n",
      "Epoch 13/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.3958 - auc: 0.8768 - val_loss: 0.4679 - val_auc: 0.8789\n",
      "Epoch 14/100\n",
      "56046/56046 [==============================] - 18s 315us/sample - loss: 0.3798 - auc: 0.8780 - val_loss: 0.3719 - val_auc: 0.8831\n",
      "Epoch 15/100\n",
      "56046/56046 [==============================] - 18s 313us/sample - loss: 0.3606 - auc: 0.8800 - val_loss: 0.3971 - val_auc: 0.8854\n",
      "Epoch 16/100\n",
      "56046/56046 [==============================] - 17s 301us/sample - loss: 0.3651 - auc: 0.8830 - val_loss: 0.3410 - val_auc: 0.8764\n",
      "Epoch 17/100\n",
      "56046/56046 [==============================] - 17s 300us/sample - loss: 0.3414 - auc: 0.8828 - val_loss: 0.3561 - val_auc: 0.8852\n",
      "Epoch 18/100\n",
      "56046/56046 [==============================] - 17s 301us/sample - loss: 0.3392 - auc: 0.8836 - val_loss: 0.3546 - val_auc: 0.8780\n",
      "Epoch 19/100\n",
      "56046/56046 [==============================] - 17s 302us/sample - loss: 0.3273 - auc: 0.8841 - val_loss: 0.4068 - val_auc: 0.8911\n",
      "Epoch 20/100\n",
      "56046/56046 [==============================] - 17s 300us/sample - loss: 0.3187 - auc: 0.8858 - val_loss: 0.4031 - val_auc: 0.8880\n",
      "Epoch 21/100\n",
      "56046/56046 [==============================] - 17s 305us/sample - loss: 0.3123 - auc: 0.8865 - val_loss: 0.4011 - val_auc: 0.8796\n",
      "Epoch 22/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.3087 - auc: 0.8876 - val_loss: 0.3002 - val_auc: 0.8877\n",
      "Epoch 23/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.2921 - auc: 0.8881 - val_loss: 0.2938 - val_auc: 0.8855\n",
      "Epoch 24/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.3059 - auc: 0.8890 - val_loss: 0.2965 - val_auc: 0.8862\n",
      "Epoch 25/100\n",
      "56046/56046 [==============================] - 17s 308us/sample - loss: 0.2990 - auc: 0.8884 - val_loss: 0.3435 - val_auc: 0.8793\n",
      "Epoch 26/100\n",
      "56046/56046 [==============================] - 17s 309us/sample - loss: 0.2709 - auc: 0.8898 - val_loss: 0.2553 - val_auc: 0.8898\n",
      "Epoch 27/100\n",
      "56046/56046 [==============================] - 17s 310us/sample - loss: 0.2588 - auc: 0.8906 - val_loss: 0.2642 - val_auc: 0.8899\n",
      "Creating predictions for fold 5/5\n",
      "Fold validation AUC: 0.8911392665816883\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "histories = []\n",
    "oof_preds_sum = np.zeros((train_df.shape[0],))\n",
    "train_preds_sum = np.zeros((train_df.shape[0],))\n",
    "test_preds_sum = np.zeros((test_df.shape[0],))\n",
    "\n",
    "for fold_num, (train_index, val_index) in tqdm(enumerate(kfold.split(train_df[features].values, train_df['target'].values)), total=N_SPLITS):\n",
    "    print(f'Fold {fold_num+1}/{N_SPLITS}:')\n",
    "    \n",
    "    X_train = train_df.loc[train_index, features].values\n",
    "    y_train = train_df.loc[train_index, 'target'].values.reshape(-1, 1)\n",
    "    X_val = train_df.loc[val_index, features].values\n",
    "    y_val = train_df.loc[val_index, 'target'].values.reshape(-1, 1)\n",
    "    \n",
    "    model = model_fn()\n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)\n",
    "    \n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_auc', mode='max', patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[early_stopping_callback])\n",
    "    histories.append(history)\n",
    "    \n",
    "    \n",
    "    print(f'Creating predictions for fold {fold_num + 1}/{N_SPLITS}')\n",
    "    val_preds = model.predict(X_val)\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(test_df[features].values)\n",
    "    \n",
    "    oof_preds_sum[val_index] += val_preds[:, 0]\n",
    "    train_preds_sum[train_index] += train_preds[:, 0]\n",
    "    test_preds_sum += test_preds[:, 0]\n",
    "    \n",
    "    val_auc = roc_auc_score(y_val, val_preds)\n",
    "    print(f'Fold validation AUC: {val_auc}')\n",
    "    print()\n",
    "    #models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'ID_code': test_df['ID_code'], 'target': test_preds_sum})\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission.csv' target='_blank'>submission.csv</a><br>"
      ],
      "text/plain": [
       "/home/eivind/workspaces/TDT05-project/submission.csv"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
